\documentclass{beamer}
\setbeamerfont{subsection in toc}{size=\footnotesize}
\usepackage{pgfpages}
%\setbeameroption{show notes on second screen=left} %enable for notes
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{listings}
%\usepackage{transparent}
\usepackage{hyperref}
\lstset{language=python,frame=single}
\usepackage{verbatim}
%\usepackage{apacite}
\usepackage[longnamesfirst]{natbib}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{relsize}
\usepackage{appendixnumberbeamer}
\usepackage{xparse}
\usepackage{multimedia}
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\usepackage{tikz}
\usetikzlibrary{matrix,backgrounds}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes,arrows}
\usetikzlibrary{positioning}

\tikzset{onslide/.code args={<#1>#2}{%
  \only<#1>{\pgfkeysalso{#2}} 
}}

\tikzstyle{block} = [rectangle, draw, fill=red!20!blue!10, 
    text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{netnode} = [circle, draw, very thick, inner sep=0pt, minimum size=0.5cm] 
\tikzstyle{relunode} = [rectangle, draw, very thick, inner sep=0pt, minimum size=0.5cm] 
    
\tikzstyle{line} = [draw, line width=1.5pt, -latex']

\pgfdeclarelayer{background}
\pgfsetlayers{background,main}

\pgfdeclarelayer{myback}
\pgfsetlayers{myback,background,main}

\usetheme[numbering=fraction]{metropolis}
\newcommand{\semitransp}[2][35]{\color{fg!#1}#2}

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}
\renewcommand*\footnoterule{}
%%\AtBeginSection[]
%%{
%%  \begin{frame}
%%    \frametitle{Table of Contents}
%%    \tableofcontents[currentsection]
%%  \end{frame}
%%}

\newcommand{\R}{\mathbb{R}}
\newcommand{\bb}[1]{{\bf\overline{#1}}}
\newcommand{\bh}[1]{{\bf\hat{#1}}}

\newcommand{\trainerr}{\mathcal{\varepsilon}_\text{train}}
\newcommand{\generr}{\mathcal{\varepsilon}_\text{test}}

\newcommand{\toptn}{{t}^\text{opt}_\text{gradient}}
\newcommand{\eoptn}{\mathcal{\varepsilon}^\text{opt}_\text{gradient}}
\newcommand{\eoptnn}{\mathcal{\varepsilon}^\text{opt}_\text{non-gradient}}

\newcommand{\wa}{{\bf{W}^{21}}}
\newcommand{\wb}{{\bf{W}^{32}}}
\newcommand{\wk}{{\bf{W}^{k(k-1)}}}
\newcommand{\ddt}{\frac{d}{dt}}
\newcommand{\ovn}{\overline{N}}
\newcommand{\rank}{\text{rank}}

\begin{document}

\title{Understanding generalization and transfer in deep linear neural networks}
\author{Andrew Lampinen}
\date{FriSem, 1/18/2019}
\frame{\titlepage}

\begin{frame}{Generalization in deep networks: ``Creativity'' from AlphaGo}
\begin{figure}
\includegraphics[width=0.5\textwidth]{figures/alphago_move_37.png}
\end{figure}
\note{This is a move that nobody has seen before in professional play, during the game commentators called it ``probably a mistake,'' but later decided it was ``beautiful.''}
\end{frame}

\begin{frame}{Generalization in humans: Past tense over-regularization}
\begin{figure}
\includegraphics[width=0.8\textwidth]{figures/past_tense.png}
\end{figure}
\note{There are many interesting phenomena like this, but there's a general pattern of learning broad features followed by progressive differentiation of lower level structure.}
\end{frame}

\begin{frame}<1>[label=gen_dyn_int]
\frametitle<1>{Generalization dynamics in deep networks}

\frametitle<2->{Generalization dynamics (intuition)}
\begin{figure}
\includegraphics[width=0.6\textwidth]{figures/conceptual_train_test.png}
\vspace{-1em}
\end{figure}
\only<2->{
\begin{itemize}[<+(2)->]
\item The strongest modes in the training data are learned first.
\item The strongest modes are the least distorted.
\item Any signal modes that contain usable signal will be stronger than the noise modes. 
\end{itemize}
}
\note{First train and test error go down together, with a slight gap, then overfitting, in between is optimal stopping.}
\end{frame}

\begin{frame}[standout]
How, why, and when do neural networks (and humans) generalize what they have learned?
\end{frame}

\begin{frame}{Outline}
\vspace{1em}
\tableofcontents
\end{frame}

\section{The theory}

\subsection{Deep linear networks}
\begin{frame}{Setting: Deep linear networks}
\begin{figure}
\centering
\begin{tikzpicture}[auto, overlay, remember picture]
\begin{scope}[shift={(0, -0.5)}]
\node at (0, -2.75) (input) {\only<3-5>{\LARGE \textbf{Go}}};
\node at (0, 2.75) (output) {\only<5>{\LARGE \textbf{Goed}}};

\node [netnode, onslide={<3-5>{fill=red!20}}] at (-1.5,-2) (i1) {};
\node [netnode, onslide={<3-5>{fill=blue!80}}] at (-0.5,-2) (i2) {};
\node [netnode, onslide={<3-5>{fill=red!75}}] at (0.5,-2) (i3) {};
\node [netnode, onslide={<3-5>{fill=blue!30}}] at (1.5,-2) (i4) {};

\node [netnode, onslide={<4-5>{fill=blue!20}}] at (-1,0) (h111) {};
\node [netnode, onslide={<4-5>{fill=red}}] at (0,0) (h112) {};
\node [netnode, onslide={<4-5>{fill=red!30}}] at (1,0) (h113) {};

\path [draw, very thick] (i1) to (h111);
\path [draw, very thick] (i1) to (h112);
\path [draw, very thick] (i1) to (h113);
\path [draw, very thick] (i2) to (h111);
\path [draw, very thick] (i2) to (h112);
\path [draw, very thick] (i2) to (h113);
\path [draw, very thick] (i3) to (h111);
\path [draw, very thick] (i3) to (h112);
\path [draw, very thick] (i3) to (h113);
\path [draw, very thick] (i4) to (h111);
\path [draw, very thick] (i4) to (h112);
\path [draw, very thick] (i4) to (h113);

\only<-5>{ 
\node [netnode, onslide={<5>{fill=red!50}}] at (-2,2) (h120) {};
\node [netnode, onslide={<5>{fill=red!10}}] at (-1,2) (h121) {};
\node [netnode, onslide={<5>{fill=blue!75}}] at (0,2) (h122) {};
\node [netnode, onslide={<5>{fill=blue!30}}] at (1,2) (h123) {};
\node [netnode, onslide={<5>{fill=blue!10}}] at (2,2) (h124) {};

\path [draw, very thick] (h111) to (h120);
\path [draw, very thick] (h111) to (h121);
\path [draw, very thick] (h111) to (h122);
\path [draw, very thick] (h111) to (h123);
\path [draw, very thick] (h111) to (h124);
\path [draw, very thick] (h112) to (h120);
\path [draw, very thick] (h112) to (h121);
\path [draw, very thick] (h112) to (h122);
\path [draw, very thick] (h112) to (h123);
\path [draw, very thick] (h112) to (h124);
\path [draw, very thick] (h113) to (h120);
\path [draw, very thick] (h113) to (h121);
\path [draw, very thick] (h113) to (h122);
\path [draw, very thick] (h113) to (h123);
\path [draw, very thick] (h113) to (h124);
}
\only<6->{

\node at (0, 0.85) (dots) {\LARGE$\bm{\vdots}$};

\node [netnode] at (-1,1.5) (h211) {};
\node [netnode] at (0,1.5) (h212) {};
\node [netnode] at (1,1.5) (h213) {};

\node [netnode] at (-2,3.5) (h120) {};
\node [netnode] at (-1,3.5) (h121) {};
\node [netnode] at (0,3.5) (h122) {};
\node [netnode] at (1,3.5) (h123) {};
\node [netnode] at (2,3.5) (h124) {};

\path [draw, very thick] (h211) to (h120);
\path [draw, very thick] (h211) to (h121);
\path [draw, very thick] (h211) to (h122);
\path [draw, very thick] (h211) to (h123);
\path [draw, very thick] (h211) to (h124);
\path [draw, very thick] (h212) to (h120);
\path [draw, very thick] (h212) to (h121);
\path [draw, very thick] (h212) to (h122);
\path [draw, very thick] (h212) to (h123);
\path [draw, very thick] (h212) to (h124);
\path [draw, very thick] (h213) to (h120);
\path [draw, very thick] (h213) to (h121);
\path [draw, very thick] (h213) to (h122);
\path [draw, very thick] (h213) to (h123);
\path [draw, very thick] (h213) to (h124);


}


%% annotations
\only<-5>{
\node at (-2.75, -1) {\LARGE$\wa$};
\node at (-2.75, 1) {\LARGE$\wb$};
}
\only<6->{
\node at (-2.75, -1) {\LARGE$\wa$};
\node at (-2.75, 2.25) {\LARGE$\wk$};
}
\only<2-5>{
\node at (2.4, -2) {\LARGE$N_1$};
\node at (2, 0) {\LARGE$N_2$};
\node at (2.9, 2) {\LARGE$N_3$};
}
\end{scope}
\end{tikzpicture}
\end{figure}
\end{frame}

\begin{frame}{Why linear?}
Linear networks are much easier to understand mathematically. They lack the full representational capacity of nonlinear networks, but exhibit similar (and nonlinear) learning dynamics.
\begin{figure}
\uncover<2->{
\only<-2>{
\includegraphics[height=0.6\textheight]{figures/progressive_differentiation.png}
}
\only<3>{
\includegraphics[height=0.6\textheight]{figures/conceptual_train_test.png}
}
}
\end{figure}
\vspace{-1em}
\uncover<2->{\footnotesize \citep{Saxe2013, Saxe2018, Lampinen2019}}
\end{frame}

\begin{frame}[standout]
Deep linear networks can be analyzed more easily, but still capture many interesting features of nonlinear networks' learning dynamics. 
\end{frame}

\subsection{Learning dynamics}
\begin{frame}{Learning dynamics}
\begin{columns}
\begin{column}{0.55\textwidth}
\only<-3>{\vspace{0.9em}}
\begin{itemize}[<+->] \itemsep 1em
\item Training data $\{(\bh{x}^\mu, \bh{y}^\mu)\}$, e.g.
    $\{(\text{talk}, \text{talked}), (\text{go}, \text{went}), \cdots\}$
\item Loss $\sum_{\mu}||\bh{y}^\mu - {\bf y}^\mu||^2$\\
      $=\sum_{\mu}||\bh{y}^\mu - \wb\wa \bh{x}^\mu||^2$
\item Batch gradient descent
    \only<-3>{$\Delta \wa  =  \lambda \sum_{\mu} \wb^T \left( \bh{y}^\mu   - \wb \wa {\bh x}^\mu   \right){\bh x}^\mu{}^T$\\[0.5em]
	      $\Delta \wb  =  \lambda \sum_{\mu} \left( \bh{y}^\mu  - \wb \wa  {\bh x}^\mu \right) {\bh x}^\mu{}^T \wa^T$}
    \only<4->{$\tau \ddt \wa  =  \wb^T \left( {\bf \Sigma}^{31} - \wb \wa {\bf \Sigma}^{11} \right)$\\[0.5em]
	      $\tau \ddt \wb = \left( {\bf \Sigma}^{31} - \wb \wa {\bf \Sigma}^{11} \right) \wa^T$}

\end{itemize}
\end{column}
\begin{column}{0.45\textwidth}
\centering
$\bf{y}^\mu$
\includegraphics[width=\textwidth]{figures/reference_network.png}
$\bh{x}^\mu$
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Structure in the data}
\vspace{2em}
\begin{columns}
\begin{column}{0.5\textwidth}
Input-Input Correlations:
${\bf\Sigma}^{11} \equiv \sum_{\mu=1}^{\overline{N}_1} {\bh x}^\mu {\bh x}^\mu{}^T \uncover<2->{= {\bf I}}$
\end{column}
\begin{column}{0.5\textwidth}
\uncover<3->{
Input-Output Correlations:
${\bf \Sigma}^{31} \equiv \sum_{\mu=1}^{\overline{N_1}} \bh{y}^\mu {\bh x}^\mu{}^T$% = \bb{W} + {\bf Z}{\bh X}^T$
}
\end{column}
\end{columns}
\begin{figure}
\centering
\uncover<4->{
\includegraphics[width=\textwidth]{figures/SVD_from_saxe2018.png}
}
\end{figure}
\uncover<4->{\footnotesize \citep{Saxe2013}, figure from \citep{Saxe2018}}
\end{frame}

\begin{frame}{Learning dynamics are driven by ${\bf\Sigma}_{31}$}
\begin{figure}
\centering
\includegraphics[width=\textwidth]{figures/SVD_from_saxe2018.png}
\end{figure}
\begin{columns}
\begin{column}{0.5\textwidth}
\includegraphics[width=\textwidth]{figures/SVD_learn_from_saxe2018.png}
\end{column}
\begin{column}{0.5\textwidth}
\centering
\uncover<2->{
$s(t,\hat s)=\frac{\hat s e^{2\hat st/\tau}}{e^{2\hat st/\tau}-1+\hat s/\epsilon}$\\[0.5em]
}
\uncover<3->{
$t(s,\hat s) = \frac{\tau}{2\hat s} 
   \ln{\frac{{\hat s}/\epsilon -1}{{\hat s}/s -1}}$
}
\end{column}
\end{columns}
{\footnotesize \citep{Saxe2013}, figure from \citep{Saxe2018}}
\end{frame}

\begin{frame}[standout]
Principal components of the training data are learned independently; stronger components are learned earlier.
\end{frame}

\subsection{Distortion of data by noise}
\begin{frame}{A noisy teacher}
Suppose we have some true labels for some ground-truth linear task:
$$\bb{y}^{\mu} = \bb{W}\bh{x}^\mu$$
To which IID gaussian noise is added to produce the training data:
$$\bh{y}^{\mu} = \bb{W}\bh{x}^\mu + \bf{z} ^ \mu$$
How well does the network learn the true task from this noisy teacher? 
\end{frame}

\begin{frame}{How the signal emerges in the noisy training data}
\vspace{-0.5em}
\begin{center}%
\only<-3>{%
\includegraphics[width=0.75\textwidth]{../../plots/paper/fig_2a_hidden.png}%
}%
\only<4->{%
\includegraphics[width=0.75\textwidth]{../../plots/paper/fig_2a.png}%
}
\uncover<2->{%
\includegraphics[width=0.428\textwidth]{../../plots/paper/fig_2c.png}%
}%
\uncover<3->{%
\includegraphics[width=0.322\textwidth]{../../plots/paper/fig_2d.png}%
}%
\end{center}
\vspace{-1em}
{\footnotesize Building on \citet{Benaych-Georges2012}}
\end{frame}


\begin{frame}{Scary math slide}
Singular value inflation:
$$
\hat{s}(\overline{s}) = \begin{cases}
{(\overline{s})^{-1}}{\sqrt{(1+\overline{s}^2)(\mathcal{A}+\overline{s}^2)}}\ & \text{if } \overline{s} > \mathcal{A}^{1/4} \\
1+\sqrt{\mathcal{A}} & \text{otherwise}.
\end{cases}
$$
Singular vector alignment:
$$\mathcal{O}(\overline{s}) = 
\begin{cases}
\left[1-
        \frac{\mathcal{A}(1+\overline{s}^2)}          
            {\overline{s}^2(\mathcal{A}+\overline{s}^2)}
\right]^{1/2} 
\left[1-
        \frac{(\mathcal{A}+\overline{s}^2)}          
            {\overline{s}^2(1+\overline{s}^2)}
\right]^{1/2}

& \text{if } \overline{s} > \mathcal{A}^{1/4} \\
0 & \text{otherwise}
\end{cases}
$$
Noise singular value distribution:
$$P(\hat{s}) = \begin{cases}
\frac{\sqrt{4\mathcal{A}-(\hat{s}^2 - (1+\mathcal{A}))^2}}{\pi \mathcal{A}\hat{s}} & \hat{s} \in [1-\sqrt{\mathcal{A}}, 1+\sqrt{\mathcal{A}}] \\
0 & \text{otherwise}.
\end{cases}
$$
\end{frame}

\begin{frame}[standout]
Noise inflates and distorts signal dimensions; weaker dimensions are distorted more. \\[1em]
The remaining dimensions are filled with noise.
\end{frame}


\subsection{Generalization dynamics}
\againframe<2->{gen_dyn_int}

\begin{frame}[standout]
The standard generalization pattern emerges naturally from the fact that stronger signals are less distorted AND learned earlier.
\end{frame}


\begin{frame}{Formulas for the train and test error}
\footnotesize
\begin{align*}
\trainerr &\equiv \frac{\sum_{\mu=1}^{\overline{N_1}} \vert\vert{\bf W \bh{x}}^\mu - \bh{y}^\mu\vert\vert^2_2}{\sum_{\mu=1}^{\overline{N_1}} \vert\vert \bh{y}^\mu \vert\vert^2_2 }\\[1em]
\uncover<2->{ &= \left[\sum_{\beta=1}^{\overline{N}_3} \hat{s}_{\beta}^2\right]^{-1} 
\left[ \sum_{\alpha=1}^{N_2} s_{\alpha}^2 +  \sum_{\beta=1}^{\overline{N}_3} \hat{s}_{\beta}^2
- 2 \sum_{\alpha=1}^{N_2} \sum_{\beta=1}^{\overline{N}_3}  s_{\alpha} \hat{s}_{\beta} \left({\bf u}^{\alpha} \cdot \bf{\hat u}^{\beta} \right) \left({\bf v}^{\alpha} \cdot \bf{\hat v}^{\beta} \right)\right]\\[3em]}
\uncover<3->{\generr &\equiv   \frac{ \left\langle \vert\vert{\bf W}\bb{x} - \bb{y} \vert\vert^2_2 \right \rangle} 
                      { \left\langle  \vert\vert \bb{y} \vert\vert^2_2  \right \rangle} \\[1em]}
\uncover<4->{ &= \left[\sum_{\beta=1}^{\overline{N}_2} \overline{s}_{\beta}^2\right]^{-1} 
\left[ \sum_{\alpha=1}^{N_2} s_{\alpha}^2 +  \sum_{\beta=1}^{\overline{N}_2} \overline{s}_{\beta}^2
- 2 \sum_{\alpha=1}^{N_2} \sum_{\beta=1}^{\overline{N}_2}  s_{\alpha} \overline{s}_{\beta} \left({\bf u}^{\alpha} \cdot \bb{u}^{\beta} \right) \left({\bf v}^{\alpha} \cdot \bb{v}^{\beta} \right)\right]}
\end{align*}
\end{frame}

\begin{frame}[standout]
Important assumption: the student is initialized with Teacher Aligned (TA) modes.
\end{frame}

\begin{frame}{Generalization dynamics (math)}
\footnotesize
\begin{align*}
\trainerr(t) &=
\frac{
{\color{green} \overbrace{\color{mDarkTeal}(N_3\! - \!N_2) \langle \hat s^2 \rangle_{\mathcal{R}_{out}}}^{\text{\small Beyond capacity}}} \!+ \! (N_2 \!-\! \overline{N}_2) \langle (s(\hat{s},t) -\hat{s})^2 \rangle_{\mathcal{R}_{in}} +
\sum_{\alpha=1}^{\overline{N}_2}
    \left[
       s_\alpha(t) -
       \hat{s}_{\alpha} \right]^2
} 
{\color{red}\underbrace{\color{mDarkTeal}\sum_{\alpha=1}^{\overline{N}_3} \hat{s}_{\alpha}^2}_{\text{\small Normalization}}}\\[2em]
\generr(t) &= 
\frac{%
(N_2 \!-\! \overline{N}_2) \langle s(\hat{s},t)^2 \rangle_{\mathcal{R}_{in}}\! + 
\sum_{\alpha=1}^{\overline{N}_2} 
    \left[
       (s_\alpha(t) - \overline{s}_{\alpha})^2  
       + 2 s_\alpha(t) \overline{s}_{\alpha}(1-\mathcal{O}(\overline{s}_\alpha))
       \right]}{\sum_{\alpha=1}^{\overline{N}_2} \overline{s}_{\alpha}^2}
\end{align*}
\end{frame}

\begin{frame}{Theory-experiment match}
\begin{figure}
\begin{subfigure}[t]{0.22\textwidth}
\includegraphics[height=0.28\textheight]{../../plots/paper/fig3_redux_E.png}
\end{subfigure}%
\begin{subfigure}[t]{0.33\textwidth}
\includegraphics[height=0.28\textheight]{../../plots/paper/fig3_redux_F.png}
\end{subfigure}%
\begin{subfigure}[t]{0.22\textwidth}
\includegraphics[height=0.28\textheight]{../../plots/paper/fig3_redux_G.png}
\end{subfigure}%
\begin{subfigure}[t]{0.22\textwidth}
\includegraphics[height=0.28\textheight]{../../plots/paper/fig3_redux_H.png}
\end{subfigure}\\
\uncover<2->{
\begin{subfigure}[t]{0.22\textwidth}
\includegraphics[height=0.28\textheight]{../../plots/paper/deep_fig_redux_E.png}
\end{subfigure}%
\begin{subfigure}[t]{0.33\textwidth}
\includegraphics[height=0.28\textheight]{../../plots/paper/deep_fig_redux_F.png}
\end{subfigure}%
\begin{subfigure}[t]{0.22\textwidth}
\includegraphics[height=0.28\textheight]{../../plots/paper/deep_fig_redux_G.png}
\end{subfigure}%
\begin{subfigure}[t]{0.22\textwidth}
\includegraphics[height=0.28\textheight]{../../plots/paper/deep_fig_redux_H.png}
\end{subfigure}
}
\end{figure}

\end{frame}


\section{Applications of the theory}

\subsection{The trouble with structure-agnostic generalization bounds}
\begin{frame}{Why do standard generalization bounds suck?}
\end{frame}

\subsection{Randomized data}
\begin{frame}{Randomized data is learned slower}
\end{frame}

\subsection{Multiple tasks \& transfer}
\begin{frame}{Multi-task learning}
\end{frame}

\subsection{Structure sensitive regularization}
\begin{frame}{Is gradient descent optimal?}
\end{frame}


\begin{frame}{Summary}

\end{frame}

\begin{frame}{Open questions}

\end{frame}

\begin{frame}[allowframebreaks]
\bibliographystyle{plainnat}
\blfootnote{\bibliography{generalization}}
\end{frame}

\appendix
\begin{frame}{Alignment time}
\begin{figure}
\centering
\begin{subfigure}[t]{0.3\textwidth}
\includegraphics[height=0.38\textheight]{../../plots/paper/supp_alignment_time_B.png}
\end{subfigure}%
\begin{subfigure}[t]{0.3\textwidth}
\includegraphics[height=0.38\textheight]{../../plots/paper/supp_alignment_time_C.png}
\end{subfigure}%
\begin{subfigure}[t]{0.4\textwidth}
\includegraphics[height=0.38\textheight]{../../plots/paper/supp_alignment_time_D.png}
\end{subfigure}\\
\begin{subfigure}[t]{0.3\textwidth}
\includegraphics[height=0.38\textheight]{../../plots/paper/supp_alignment_time_F.png}
\end{subfigure}%
\begin{subfigure}[t]{0.3\textwidth}
\includegraphics[height=0.38\textheight]{../../plots/paper/supp_alignment_time_G.png}
\end{subfigure}%
\begin{subfigure}[t]{0.4\textwidth}
\includegraphics[height=0.38\textheight]{../../plots/paper/supp_alignment_time_H.png}
\end{subfigure}
\end{figure}

\end{frame}

\end{document}


