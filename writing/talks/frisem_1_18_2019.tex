\documentclass{beamer}
\setbeamerfont{subsection in toc}{size=\footnotesize}
\usepackage{pgfpages}
%\setbeameroption{show notes on second screen=left} %enable for notes
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{listings}
%\usepackage{transparent}
\usepackage{hyperref}
\lstset{language=python,frame=single}
\usepackage{verbatim}
%\usepackage{apacite}
\usepackage[longnamesfirst]{natbib}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{relsize}
\usepackage{appendixnumberbeamer}
\usepackage{xparse}
\usepackage{multimedia}
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\usepackage{tikz}
\usetikzlibrary{matrix,backgrounds}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes,arrows}
\usetikzlibrary{positioning}

\captionsetup[subfigure]{labelformat=empty}

\tikzset{onslide/.code args={<#1>#2}{%
  \only<#1>{\pgfkeysalso{#2}} 
}}

\tikzstyle{block} = [rectangle, draw, fill=red!20!blue!10, 
    text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{netnode} = [circle, draw, very thick, inner sep=0pt, minimum size=0.5cm] 
\tikzstyle{relunode} = [rectangle, draw, very thick, inner sep=0pt, minimum size=0.5cm] 
    
\tikzstyle{line} = [draw, line width=1.5pt, -latex']

\pgfdeclarelayer{background}
\pgfsetlayers{background,main}

\pgfdeclarelayer{myback}
\pgfsetlayers{myback,background,main}

\usetheme[numbering=fraction]{metropolis}
\newcommand{\semitransp}[2][35]{\color{fg!#1}#2}

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}
\renewcommand*\footnoterule{}
%%\AtBeginSection[]
%%{
%%  \begin{frame}
%%    \frametitle{Table of Contents}
%%    \tableofcontents[currentsection]
%%  \end{frame}
%%}

\newcommand{\R}{\mathbb{R}}
\newcommand{\bb}[1]{{\bf\overline{#1}}}
\newcommand{\bh}[1]{{\bf\hat{#1}}}

\newcommand{\trainerr}{\mathcal{\varepsilon}_\text{train}}
\newcommand{\generr}{\mathcal{\varepsilon}_\text{test}}

\newcommand{\toptn}{{t}^\text{opt}_\text{gradient}}
\newcommand{\eoptn}{\mathcal{\varepsilon}^\text{opt}_\text{gradient}}
\newcommand{\eoptnn}{\mathcal{\varepsilon}^\text{opt}_\text{non-gradient}}

\newcommand{\wa}{{\bf{W}^{21}}}
\newcommand{\wb}{{\bf{W}^{32}}}
\newcommand{\wk}{{\bf{W}^{k(k-1)}}}
\newcommand{\ddt}{\frac{d}{dt}}
\newcommand{\ovn}{\overline{N}}
\newcommand{\rank}{\text{rank}}

%% brewer set2
\definecolor{bred}{HTML}{e41a1c}
\definecolor{bblue}{HTML}{377eb8}
\definecolor{bgreen}{HTML}{4daf4a}
\definecolor{bpurp}{HTML}{984ea3}
\definecolor{borng}{HTML}{ff7f00}


\tikzstyle{data0} = [circle, fill=borng]
\tikzstyle{data1} = [circle, fill=bpurp]

\begin{document}

\title{Understanding generalization and transfer in deep linear neural networks}
\author{Andrew Lampinen}
\date{FriSem, 1/18/2019}
\frame{\titlepage}

\begin{frame}{An intuitive overview of:}
\begin{figure}
\includegraphics[width=\textwidth]{figures/paper_title.png}
\end{figure}
\end{frame}

\begin{frame}{Generalization in deep networks: Image segmentation}
\begin{figure}
\includegraphics[width=0.8\textwidth]{figures/other_peoples/semantic_segmentation.png}
\end{figure}
\end{frame}

\begin{frame}{Generalization in deep networks: ``Creativity'' from AlphaGo}
\begin{figure}
\includegraphics[width=0.5\textwidth]{figures/alphago_move_37.png}
\end{figure}
\note{This is a move that nobody has seen before in professional play, during the game commentators called it ``probably a mistake,'' but later decided it was ``beautiful.''}
\end{frame}

\begin{frame}{These results are theoretically puzzling}
\begin{figure}
\includegraphics[width=0.8\textwidth]{figures/VC.png}
\end{figure}
\end{frame}

\begin{frame}<1>[label=gen_dyn_int]
\frametitle<1>{Generalization dynamics in deep networks}

\frametitle<2->{Generalization dynamics (intuition)}
\begin{figure}
\only<1-2, 7->{
\includegraphics[width=0.6\textwidth]{figures/conceptual_train_test.png}
\vspace{-1em}
}
\only<3-6>{
\vspace{1.4em}
\includegraphics[width=0.6\textwidth]{../../plots/paper/fig_2a.png}%
\includegraphics[width=0.4\textwidth]{../../plots/paper/fig_1b.png}
\vspace{1.4em}
}
\end{figure}
\only<2->{
\begin{itemize}[<+(3)->]
\item The strongest modes in the training data are learned first.
\item The strongest modes are the least distorted.
\item Any signal modes that contain usable signal will be stronger than the noise modes. 
\end{itemize}
}
\note{First train and test error go down together, with a slight gap, then overfitting, in between is optimal stopping.}
\end{frame}

\begin{frame}{Generalization dynamics in humans: Over-regularization}
\begin{figure}
\includegraphics[width=0.8\textwidth]{figures/past_tense.png}
\end{figure}
\note{There are many interesting phenomena like this, but there's a general pattern of learning broad features followed by progressive differentiation of lower level structure.}
\end{frame}

\begin{frame}[standout]
How, when, and why do neural networks (and humans) generalize well?
\end{frame}

\begin{frame}{Outline}
\vspace{1em}
\tableofcontents
\end{frame}

\section{The theory}

\subsection{Deep linear networks}
\begin{frame}<2->{Setting: Deep linear networks}
\begin{figure}
\centering
\begin{tikzpicture}[auto, overlay, remember picture]
\begin{scope}[shift={(0, -0.5)}]
\node at (0, -2.75) (input) {\only<3-5>{\LARGE \textbf{Go}}};
\node at (0, 2.75) (output) {\only<5>{\LARGE \textbf{Goed}}};

\node [netnode, onslide={<3-5>{fill=red!20}}] at (-1.5,-2) (i1) {};
\node [netnode, onslide={<3-5>{fill=blue!80}}] at (-0.5,-2) (i2) {};
\node [netnode, onslide={<3-5>{fill=red!75}}] at (0.5,-2) (i3) {};
\node [netnode, onslide={<3-5>{fill=blue!30}}] at (1.5,-2) (i4) {};

\node [netnode, onslide={<4-5>{fill=blue!20}}] at (-1,0) (h111) {};
\node [netnode, onslide={<4-5>{fill=red}}] at (0,0) (h112) {};
\node [netnode, onslide={<4-5>{fill=red!30}}] at (1,0) (h113) {};

\path [draw, very thick] (i1) to (h111);
\path [draw, very thick] (i1) to (h112);
\path [draw, very thick] (i1) to (h113);
\path [draw, very thick] (i2) to (h111);
\path [draw, very thick] (i2) to (h112);
\path [draw, very thick] (i2) to (h113);
\path [draw, very thick] (i3) to (h111);
\path [draw, very thick] (i3) to (h112);
\path [draw, very thick] (i3) to (h113);
\path [draw, very thick] (i4) to (h111);
\path [draw, very thick] (i4) to (h112);
\path [draw, very thick] (i4) to (h113);

\only<-5>{ 
\node [netnode, onslide={<5>{fill=red!50}}] at (-2,2) (h120) {};
\node [netnode, onslide={<5>{fill=red!10}}] at (-1,2) (h121) {};
\node [netnode, onslide={<5>{fill=blue!75}}] at (0,2) (h122) {};
\node [netnode, onslide={<5>{fill=blue!30}}] at (1,2) (h123) {};
\node [netnode, onslide={<5>{fill=blue!10}}] at (2,2) (h124) {};

\path [draw, very thick] (h111) to (h120);
\path [draw, very thick] (h111) to (h121);
\path [draw, very thick] (h111) to (h122);
\path [draw, very thick] (h111) to (h123);
\path [draw, very thick] (h111) to (h124);
\path [draw, very thick] (h112) to (h120);
\path [draw, very thick] (h112) to (h121);
\path [draw, very thick] (h112) to (h122);
\path [draw, very thick] (h112) to (h123);
\path [draw, very thick] (h112) to (h124);
\path [draw, very thick] (h113) to (h120);
\path [draw, very thick] (h113) to (h121);
\path [draw, very thick] (h113) to (h122);
\path [draw, very thick] (h113) to (h123);
\path [draw, very thick] (h113) to (h124);
}
\only<6->{

\node at (0, 0.85) (dots) {\LARGE$\bm{\vdots}$};

\node [netnode] at (-1,1.5) (h211) {};
\node [netnode] at (0,1.5) (h212) {};
\node [netnode] at (1,1.5) (h213) {};

\node [netnode] at (-2,3.5) (h120) {};
\node [netnode] at (-1,3.5) (h121) {};
\node [netnode] at (0,3.5) (h122) {};
\node [netnode] at (1,3.5) (h123) {};
\node [netnode] at (2,3.5) (h124) {};

\path [draw, very thick] (h211) to (h120);
\path [draw, very thick] (h211) to (h121);
\path [draw, very thick] (h211) to (h122);
\path [draw, very thick] (h211) to (h123);
\path [draw, very thick] (h211) to (h124);
\path [draw, very thick] (h212) to (h120);
\path [draw, very thick] (h212) to (h121);
\path [draw, very thick] (h212) to (h122);
\path [draw, very thick] (h212) to (h123);
\path [draw, very thick] (h212) to (h124);
\path [draw, very thick] (h213) to (h120);
\path [draw, very thick] (h213) to (h121);
\path [draw, very thick] (h213) to (h122);
\path [draw, very thick] (h213) to (h123);
\path [draw, very thick] (h213) to (h124);


}


%% annotations
\only<-5>{
\node at (-2.75, -1) {\LARGE$\wa$};
\node at (-2.75, 1) {\LARGE$\wb$};
}
\only<6->{
\node at (-2.75, -1) {\LARGE$\wa$};
\node at (-2.75, 2.25) {\LARGE$\wk$};
}
\only<-5>{
\node at (2.4, -2) {\LARGE$N_1$};
\node at (2, 0) {\LARGE$N_2$};
\node at (2.9, 2) {\LARGE$N_3$};
}
\end{scope}
\end{tikzpicture}
\end{figure}
\end{frame}

\begin{frame}[standout]
Deep networks behave similarly to single-hidden-layer ones in most respects, I will show you when they don't.
\end{frame}

\begin{frame}{Why linear?}
Linear networks are much easier to understand mathematically. They lack the full representational capacity of nonlinear networks, but exhibit similar (and nonlinear) learning dynamics.
\begin{figure}
\uncover<2->{
\only<-2>{
\includegraphics[height=0.6\textheight]{figures/progressive_differentiation.png}
}
\only<3>{
\includegraphics[height=0.6\textheight]{figures/conceptual_train_test.png}
}
}
\end{figure}
\vspace{-1em}
\uncover<2->{\footnotesize \citep{Saxe2013, Saxe2018, Lampinen2019}}
\end{frame}

\begin{frame}[standout]
Deep linear networks can be analyzed more easily, but still capture many interesting features of nonlinear networks' learning. \\[1em]
Every empirical finding I'll present has been demonstrated in the nonlinear case.
\end{frame}

\subsection{Learning dynamics}
\begin{frame}{Learning dynamics}
\begin{columns}
\begin{column}{0.55\textwidth}
\begin{itemize}[<+->] \itemsep 1.5em
\item Training data $\{(\bh{x}, \bh{y})\}$, e.g.
    $\{(\text{talk}, \text{talked}), (\text{go}, \text{went}), \cdots\}$
\item Squared error $||\bh{y} - {\bf y}||^2$
\item Batch gradient descent
    \only<-3>{$\Delta \wa  =  \lambda \sum_{\mu} \wb^T \left( \bh{y}^\mu   - \wb \wa {\bh x}^\mu   \right){\bh x}^\mu{}^T$}
    \only<4->{$\tau \ddt \wa  =  \wb^T \left( {\bf \Sigma}^{yx} - \wb \wa {\bf \Sigma}^{xx} \right)$}
\end{itemize}
\end{column}
\begin{column}{0.45\textwidth}
\centering
$\bf{y}$
\includegraphics[width=\textwidth]{figures/reference_network_2.png}
$\bh{x}$
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Structure in the data}
\vspace{2em}
\begin{columns}
\begin{column}{0.5\textwidth}
Input feature correlations:
${\bf\Sigma}^{xx} \equiv \sum_{\mu=1}^{\overline{N}_1} {\bh x}^\mu {\bh x}^\mu{}^T \uncover<2->{= {\bf I}}$
\end{column}
\begin{column}{0.5\textwidth}
\uncover<3->{
Input-output correlations:
${\bf \Sigma}^{yx} \equiv \sum_{\mu=1}^{\overline{N_1}} \bh{y}^\mu {\bh x}^\mu{}^T$% = \bb{W} + {\bf Z}{\bh X}^T$
}
\end{column}
\end{columns}
\begin{figure}
\centering
\uncover<4->{
\only<-4>{
\includegraphics[width=\textwidth]{figures/SVD_from_saxe2018_masked.png}
}
\only<5->{
\includegraphics[width=\textwidth]{figures/SVD_from_saxe2018.png}
}
}
\end{figure}
\uncover<4->{\footnotesize \citep{Saxe2013}, figure from \citep{Saxe2018}}
\end{frame}

\begin{frame}{Learning dynamics of linear networks are driven by ${\bf\Sigma}_{yx}$}
\begin{figure}
\centering
\includegraphics[width=\textwidth]{figures/SVD_from_saxe2018.png}
\end{figure}
\begin{columns}
\begin{column}{0.5\textwidth}
\includegraphics[width=\textwidth]{figures/SVD_learn_from_saxe2018.png}
\end{column}
\begin{column}{0.5\textwidth}
\uncover<2->{
\includegraphics[width=0.75\textwidth]{../../plots/paper/fig_1b.png}
}
\end{column}
\end{columns}
{\footnotesize \citep{Saxe2013}, figures \citep{Saxe2018, Lampinen2019}}
\end{frame}

\begin{frame}[standout]
Principal components of the training data are learned independently; stronger components are learned earlier.
\end{frame}

\subsection{Distortion of data by noise}
\begin{frame}{How do the training data relate to the ground truth?}
\only<-4>{
\begin{figure}
\centering
\only<1-3>{
\includegraphics[width=\textwidth]{figures/SVD_from_saxe2018.png}
}
\only<4>{
\includegraphics[width=\textwidth]{figures/SVD_from_saxe2018_noisy.png}
}
\end{figure}
\begin{columns}
\centering
\begin{column}{0.4\textwidth}
\uncover<2-4> {
\includegraphics[width=\textwidth]{figures/tree1.jpg}
}
\end{column}
\begin{column}{0.4\textwidth}
\uncover<3-4> {
\includegraphics[width=\textwidth]{figures/tree2.jpg}
}
\end{column}
\end{columns}
}
\only<5->{
Suppose we have some true labels for some ground-truth (and low-rank) linear task:
$$\bb{y}^{\mu} = \bb{W}\bh{x}^\mu$$
To which IID gaussian noise is added to produce the training data:
$$\bh{y}^{\mu} = \bb{W}\bh{x}^\mu + \bf{z} ^ \mu$$
How well does the network learn the true task from this noisy teacher? 
}
\end{frame}

\begin{frame}[label=signal_from_noise]
\frametitle{How the signal emerges in the noisy training data}
\vspace{-0.5em}
\begin{center}%
\includegraphics[width=0.428\textwidth]{../../plots/paper/fig_2c.png}%
\uncover<2->{%
\includegraphics[width=0.322\textwidth]{../../plots/paper/fig_2d.png}%
}\\
\uncover<3->{
\only<-3>{%
\includegraphics[width=0.75\textwidth]{../../plots/paper/fig_2a_hidden.png}%
}%
\only<4>{%
\includegraphics[width=0.75\textwidth]{../../plots/paper/fig_2a.png}%
}
}
\end{center}
\vspace{-1em}
{\footnotesize $\bar{s}$ is the $\text{SNR}$. This builds on \citet{Benaych-Georges2012}.}

\end{frame}


\begin{frame}{Scary math slide}
Singular value inflation:
$$
\hat{s}(\overline{s}) = \begin{cases}
{(\overline{s})^{-1}}{\sqrt{(1+\overline{s}^2)(\mathcal{A}+\overline{s}^2)}}\ & \text{if } \overline{s} > \mathcal{A}^{1/4} \\
1+\sqrt{\mathcal{A}} & \text{otherwise}.
\end{cases}
$$
Singular vector alignment:
$$\mathcal{O}(\overline{s}) = 
\begin{cases}
\left[1-
        \frac{\mathcal{A}(1+\overline{s}^2)}          
            {\overline{s}^2(\mathcal{A}+\overline{s}^2)}
\right]^{1/2} 
\left[1-
        \frac{(\mathcal{A}+\overline{s}^2)}          
            {\overline{s}^2(1+\overline{s}^2)}
\right]^{1/2}

& \text{if } \overline{s} > \mathcal{A}^{1/4} \\
0 & \text{otherwise}
\end{cases}
$$
Noise singular value distribution:
$$P(\hat{s}) = \begin{cases}
\frac{\sqrt{4\mathcal{A}-(\hat{s}^2 - (1+\mathcal{A}))^2}}{\pi \mathcal{A}\hat{s}} & \hat{s} \in [1-\sqrt{\mathcal{A}}, 1+\sqrt{\mathcal{A}}] \\
0 & \text{otherwise}.
\end{cases}
$$
\end{frame}

\begin{frame}[standout]
Noise inflates and distorts signal dimensions; weaker dimensions are distorted more. \\[1em]
Non-signal dimensions are filled with noise.
\end{frame}


\subsection{Generalization dynamics}
\againframe<2->{gen_dyn_int}

\begin{frame}[standout]
Stronger signals are less distorted AND learned earlier than weaker signals or noise. \\[1em]
Thus optimal stopping is a powerful regularizer.
\end{frame}


\begin{frame}<1>[label=gen_dyn_math]
\frametitle{Generalization dynamics (math)}
\footnotesize
\begin{align*}
\uncover<2->{
\trainerr(t) &=
\frac{
{\color{bred} \overbrace{\color{mDarkTeal}(N_3\! - \!N_2) \langle \hat s^2 \rangle_{\mathcal{R}_{out}}}^{\text{\small Beyond capacity}}} \!+ \! {\color{bblue} \overbrace{\color{mDarkTeal}(N_2 \!-\! \overline{N}_2) \langle (s(\hat{s},t) -\hat{s})^2 \rangle_{\mathcal{R}_{in}}}^{\text{\small Fitting noise}} } +
{ \color{bpurp} \overbrace{\color{mDarkTeal}
\sum_{\alpha=1}^{\overline{N}_2}
    \left[
       s_\alpha(t) -
       \hat{s}_{\alpha} \right]^2
}^{\text{\small Fitting signal}}}} 
{\color{bgreen}\underbrace{\color{mDarkTeal}\sum_{\alpha=1}^{\overline{N}_3} \hat{s}_{\alpha}^2}_{\text{\small Normalization}}}\\[1em]
}
\uncover<3->{
\generr(t) &= 
\frac{%
{\color{bblue} \overbrace{\color{mDarkTeal} (N_2 \!-\! \overline{N}_2) \langle s(\hat{s},t)^2 \rangle_{\mathcal{R}_{in}}}^{\text{\small Overfitting noise}}}\! + 
{\color{bpurp}
\overbrace{\color{mDarkTeal}\sum_{\alpha=1}^{\overline{N}_2} 
    \left[
       (s_\alpha(t) - \overline{s}_{\alpha})^2  
       + 2 s_\alpha(t) \overline{s}_{\alpha}(1-\mathcal{O}(\overline{s}_\alpha))
       \right]}^{\text{\small Fitting distorted signal}}}}
{\color{bgreen}\underbrace{\color{mDarkTeal}\sum_{\alpha=1}^{\overline{N}_2} \overline{s}_{\alpha}^2}_{\text{\small Normalization}}}}
\end{align*}
\end{frame}

\begin{frame}[standout]
Important assumption: the student is initialized with Teacher Aligned (TA) modes. \\[1em]
We'll show that random initializations are well-approximated by this assumption.
\end{frame}

\againframe<2->{gen_dyn_math}

\begin{frame}<-2>[label=theory_experiment]
\frametitle<-2>{Theory-experiment match}
\frametitle<3->{Theory-experiment match (deeper)}
\begin{figure}
\only<1>{
\begin{subfigure}[t]{0.4\textwidth}
\caption{\bf  \phantom{blah} Log train error}
\includegraphics[height=0.5\textheight]{../../plots/paper/fig3_redux_E.png}
\end{subfigure}%
\begin{subfigure}[t]{0.6\textwidth}
\caption{\bf Log test error \phantom{blahblah}}
\includegraphics[height=0.5\textheight]{../../plots/paper/fig3_redux_F.png}
\end{subfigure}%
}
\only<2>{
\begin{subfigure}[t]{0.44\textwidth}
\includegraphics[height=0.55\textheight]{../../plots/paper/fig3_redux_G.png}
\end{subfigure}%
\begin{subfigure}[t]{0.44\textwidth}
\includegraphics[height=0.55\textheight]{../../plots/paper/fig3_redux_H.png}
\end{subfigure}
}
\only<3-4>{
\begin{subfigure}[t]{0.4\textwidth}
\only<3>{
\caption{\bf  \phantom{blah} Log train error}
\includegraphics[height=0.5\textheight]{../../plots/paper/deep_fig_redux_E.png}
}
\only<4>{
\caption{\bf \phantom{blah} Randomly initialized}
\includegraphics[height=0.5\textheight]{../../plots/paper/deep_fig_redux_F_unaligned.png}
}
\end{subfigure}%
\begin{subfigure}[t]{0.6\textwidth}
\only<3>{
\caption{\bf Log test error \phantom{blahblah}}
}
\only<4>{
\caption{\bf Theory \& TA \phantom{blahblah}}
}
\includegraphics[height=0.5\textheight]{../../plots/paper/deep_fig_redux_F.png}
\end{subfigure}%
}
\only<5>{
\begin{subfigure}[t]{0.44\textwidth}
\includegraphics[height=0.55\textheight]{../../plots/paper/deep_fig_redux_G.png}
\end{subfigure}%
\begin{subfigure}[t]{0.44\textwidth}
\includegraphics[height=0.55\textheight]{../../plots/paper/deep_fig_redux_H.png}
\end{subfigure}
}
\end{figure}
\end{frame}

\begin{frame}[standout]
The theory matches the TA, and randomly initialized networks are similar but lag.
\end{frame}

\againframe<3->{theory_experiment}

\begin{frame}[standout]
Alignment is slower in deep networks, but many key features of the trajectories still match between random and TA/theory.
\end{frame}


\begin{frame}{Interim summary}
\begin{itemize}[<+->]
\item When noise is added to a low-rank dataset: 
    \begin{itemize}
    \item The signal is inflated and distorted
    \item Weaker signal modes are distorted more than strong ones.
    \item The remaining modes are filled with noise that is weaker than any usable signal.  
    \end{itemize}
\item When a linear network learns from data, it learns the strongest modes first.
\item Therefore the most important and most veridical structure is learned first, followed by less important structure and noise.
\item This yields the classic generalization curves:
    \begin{itemize}
    \item Train and test error decrease together, but with a gap. 
    \item Train error continues to decrease, but test error reverses and begins increasing. 
    \end{itemize}
\item Thus optimal stopping is a powerful regularizer.
\end{itemize}
\end{frame}

\section{Applications}

\subsection{The trouble with structure-agnostic generalization bounds}
\begin{frame}{Why do standard theoretical bounds on generalization suck?}
\begin{figure}
\centering
\only<1>{
\includegraphics[width=0.8\textwidth]{figures/VC.png}
}
\only<10>{
\includegraphics[width=0.8\textwidth]{figures/other_peoples/semantic_segmentation.png}
}
\only<11>{
\includegraphics[width=0.8\textwidth]{figures/other_peoples/DQN.png}
}

\begin{tikzpicture}[auto, overlay, remember picture]
\only<2-9>{
\node [data0] at (2, 1.8) {};
\node [data0] at (0, 2) {};
\node [data0] at (0.2, 0.7) {};
\node [data0] at (0.1, -0.1) {};
\node [data0] at (3, 2.1) {};
\node [data0] at (4, -1) {};
\node [data0] at (3, -0.2) {};
\node [data0] at (3.3, 0.3) {};
\node [data0] at (-1, 3) {};
\node [data0] at (-0.7, 1.9) {};
\node [data0] at (2, -3) {};

\node [data1] at (-2, 2) {};
\node [data1] at (0, -2) {};
\node [data1] at (-0.6, -0.3) {};
\node [data1] at (-0.1, -0.7) {};
\node [data1] at (3, -1.7) {};
\node [data1] at (-3, -2.7) {};
\node [data1] at (4.1, -1.8) {};
\node [data1] at (3, -2.2) {};
\node [data1] at (-3, 0.8) {};
\node [data1] at (-1, -1) {};
\node [data1] at (2.5, -3.5) {};
\node [data1] at (1.5, -1) {};
}

\only<3, 6>{
\draw [ultra thick] (-3, 3) -- (4.5, -2.5); 
}
\only<4>{
\draw [ultra thick] (-4, 1) -- (-3, 3.1) -- (-1.5, 2.2) -- (-2, 1.3) -- (0.3, 1.6) -- (-1, 0.6) -- (-0.3, -0.3) -- (0.5, -0.7) -- (1.5, -4) -- (2.3, -4) -- (2.3, -2.5) -- (0.8, -0.4) -- (1.2, 1) -- (2.5, -0.8) -- (4.5, -1.5); 
}
\only<7>{
\draw [ultra thick] (-1.9, 3.4) -- (-0.3, -0.3) -- (4.5, -1.5); 
}
\only<5,8-9>{
\draw [ultra thick] (-1.9, 3.4) -- (-3, 3.3) -- (-1, 2.5) -- (-4, -3) -- (-0.7, 0.3) -- (-0.3, -0.3) -- (0.5, -0.5) -- (1, 1.5) -- (2, 0) -- (1.5, -4) -- (2.3, -4)  -- (2.5, -1) -- (4.5, -1.5); 
}

\only<9> {
\draw [bred, line width=20pt] (-4, -4) -- (3.7, 3.7);
\draw [bred, line width=20pt] (-4, 3.7) -- (3.7, -4);
}
\end{tikzpicture}

\end{figure}
\end{frame}

\begin{frame}[standout]
Generalization bounds suck because they completely ignore structure in the data.\\[1em]
This is partly because modern tasks are much richer than binary classification.
\end{frame}

\subsection{Randomized data}
\begin{frame}{Memorization is slower}
\begin{figure}
\centering
\only<1>{
\includegraphics[height=0.7\textheight]{figures/other_peoples/zhang_2017_slowdown.png}

{\footnotesize \citep{Zhang2016, Arpit2017}}
}
\only<2>{
\includegraphics[width=0.75\textwidth]{../../plots/paper/randomized_fig_A.png}
}
\only<3->{
\begin{subfigure}[t]{0.5\textwidth}
\includegraphics[width=\textwidth]{../../plots/paper/randomized_fig_A.png}
\end{subfigure}%%
\begin{subfigure}[t]{0.5\textwidth}
\only<3->{%%
\includegraphics[width=\textwidth]{../../plots/paper/randomized_fig_B.png}
}
\end{subfigure}
}
\end{figure}
\end{frame}

\begin{frame}[standout]
Memorization is slower because randomizing the labels spreads the variance of strong signal modes out fairly uniformly, and the strongest modes are learned first. 
\end{frame}

\begin{frame}[standout]
It's the dataset \& dynamics, as well as the architecture, that drive good generalization.
\end{frame}

\subsection{Multiple tasks \& transfer}
\begin{frame}{Multi-task learning}
\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{figures/other_peoples/DQN.png}
\begin{tikzpicture}[auto, overlay, remember picture]
\only<2-3>{
\node at (0, 5) (tp) {Temporal prediction};
\path [draw, very thick, ->] (-1.8, 3.4) to (tp);
}
\only<3>{
\node [text width=3cm] at (0, -2) (speech) {``I'm getting the key for the door.''};
\path [draw, very thick, ->] (-1.8, 0) to (speech);
}
\end{tikzpicture}
\end{figure}
\end{frame}

\begin{frame}{Linear networks with multiple heads}
\begin{figure}
\centering
\begin{tikzpicture}[auto, remember picture]
\begin{scope}
\node at (0, -3) (input) {\includegraphics[width=1cm]{figures/alphago_move_37.png}};
\node at (0, 3) (output) {\only<1>{\LARGE \phantom{Play}}\only<2->{\LARGE {Play at C11}}};

\node [netnode] at (-1.5,-2) (i1) {};
\node [netnode] at (-0.5,-2) (i2) {};
\node [netnode] at (0.5,-2) (i3) {};
\node [netnode] at (1.5,-2) (i4) {};

\node [netnode] at (-1,0) (h111) {};
\node [netnode] at (0,0) (h112) {};
\node [netnode] at (1,0) (h113) {};

\path [draw, very thick] (i1) to (h111);
\path [draw, very thick] (i1) to (h112);
\path [draw, very thick] (i1) to (h113);
\path [draw, very thick] (i2) to (h111);
\path [draw, very thick] (i2) to (h112);
\path [draw, very thick] (i2) to (h113);
\path [draw, very thick] (i3) to (h111);
\path [draw, very thick] (i3) to (h112);
\path [draw, very thick] (i3) to (h113);
\path [draw, very thick] (i4) to (h111);
\path [draw, very thick] (i4) to (h112);
\path [draw, very thick] (i4) to (h113);

\node [netnode] at (-2,2) (h120) {};
\node [netnode] at (-1,2) (h121) {};
\node [netnode] at (0,2) (h122) {};
\node [netnode] at (1,2) (h123) {};
\node [netnode] at (2,2) (h124) {};

\path [draw, very thick] (h111) to (h120);
\path [draw, very thick] (h111) to (h121);
\path [draw, very thick] (h111) to (h122);
\path [draw, very thick] (h111) to (h123);
\path [draw, very thick] (h111) to (h124);
\path [draw, very thick] (h112) to (h120);
\path [draw, very thick] (h112) to (h121);
\path [draw, very thick] (h112) to (h122);
\path [draw, very thick] (h112) to (h123);
\path [draw, very thick] (h112) to (h124);
\path [draw, very thick] (h113) to (h120);
\path [draw, very thick] (h113) to (h121);
\path [draw, very thick] (h113) to (h122);
\path [draw, very thick] (h113) to (h123);
\path [draw, very thick] (h113) to (h124);

\only<3->{
\node [netnode, onslide={<4>{opacity=0.15}}] at (6,2) (oth122) {};
\node [netnode, onslide={<4>{opacity=0.15}}] at (5,2) (oth123) {};
\node [netnode, onslide={<4>{opacity=0.15}}] at (4,2) (oth124) {};

\node [onslide={<4>{opacity=0.15}}] at (5, 3) (output) {\only<2->{\LARGE {This move is defensive}}};

\path [draw, very thick, onslide={<4>{opacity=0.15}}] (h111) to (oth122);
\path [draw, very thick, onslide={<4>{opacity=0.15}}] (h111) to (oth123);
\path [draw, very thick, onslide={<4>{opacity=0.15}}] (h111) to (oth124);
\path [draw, very thick, onslide={<4>{opacity=0.15}}] (h112) to (oth122);
\path [draw, very thick, onslide={<4>{opacity=0.15}}] (h112) to (oth123);
\path [draw, very thick, onslide={<4>{opacity=0.15}}] (h112) to (oth124);
\path [draw, very thick, onslide={<4>{opacity=0.15}}] (h113) to (oth122);
\path [draw, very thick, onslide={<4>{opacity=0.15}}] (h113) to (oth123);
\path [draw, very thick, onslide={<4>{opacity=0.15}}] (h113) to (oth124);
}

\end{scope}
\end{tikzpicture}
\end{figure}
\end{frame}

\begin{frame}{Multi-task effects on generalization}
\only<1>{
Transfer depends only on input feature alignment and SNRs!
\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{../poster/transfer_pros_cons.png}
\end{figure}
}
\only<2-4>{
{\bf Target task is:}
\begin{figure}
\vspace{-2em}
\centering
\begin{subfigure}[t]{0.3\textwidth}
\caption{\bf Very noisy}
\includegraphics[width=\textwidth]{../../plots/paper/fig_5a.png}
\end{subfigure}%
\begin{subfigure}[t]{0.3\textwidth}
\caption{\bf \only<3->{Somewhat noisy}}
\includegraphics[width=\textwidth]{../../plots/paper/fig_5b.png}
\end{subfigure}%
\begin{subfigure}[t]{0.4\textwidth}
\caption{\bf \only<4->{Very clean\phantom{blah}}}
\includegraphics[width=\textwidth]{../../plots/paper/fig_5c.png}
\end{subfigure}
\end{figure}
}
\begin{tikzpicture}[auto, overlay, remember picture]
\only<2->{
\fill [white] (1, 0.7) rectangle (9.5, 1.0);
\node at (2, 0.8) {\tiny alignment};
\node at (5.25, 0.8) {\tiny alignment};
\node at (8.4, 0.8) {\tiny alignment};
}
\only<2>{
\fill [white] (3.2, 0.7) rectangle (7, 3.85);
}
\only<2-3>{
\fill [white] (6.5, 0.7) rectangle (9.5, 3.85);
}
\end{tikzpicture}
\end{frame}

\begin{frame}[standout]
Multi-task learning has benefits \& costs.\\[1em]
It's more beneficial when the target task is low SNR, and the auxiliary tasks are well aligned.
\end{frame}

\begin{frame}{Transfer in humans}
Is transfer beneficial to humans?
\begin{itemize}[<+->] \itemsep 1em
\item Human small data learning is in the low SNR regime -- small datasets are inherently lower SNR.
\item Many of our tasks are well aligned.
\item In fact, they are often {\bf culturally constructed} to be well aligned.
\end{itemize}
\end{frame}

\begin{frame}[standout]
Data-efficient human learning is in the regime where transfer is most beneficial.
\end{frame}


\subsection{Structure sensitive regularization}
\begin{frame}{Is optimally-stopping gradient descent optimal?}
\only<1>{
\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{figures/conceptual_train_test.png}
\end{figure}
}
\only<2-3>{
\begin{figure}
\centering
\includegraphics[width=0.428\textwidth]{../../plots/paper/fig_2c.png}%
\includegraphics[width=0.322\textwidth]{../../plots/paper/fig_2d.png}
\end{figure}
\uncover<3->{
\begin{itemize}
\item The actual optimal singular value for a distorted mode is not $\hat{s}$, but the smaller value:
$$\overline{s} \mathcal{O}(\overline{s})$$
\item Gradient descent cannot obtain this for all modes, even with $\ell_p$ regularization.
\end{itemize}
}}
\only<4>{
\begin{figure}
\centering
\includegraphics[height=0.7\textheight]{../../plots/paper/theory_only_fig3_B.png}%
\end{figure}
}
\end{frame}

\begin{frame}[standout]
Even in the linear case, SGD (with $\ell_p$ regularization) is provably sub-optimal.\\[1em]
Our regularization that is sensitive to structure in the data is better.
\end{frame}

\begin{frame}{Summary}
\begin{itemize}[<+->]
\item Generalization dynamics:
    \begin{itemize}
    \item are driven by the data structure.
    \item Noise in the data inflates and distorts signal modes, and adds pure noise modes.
    \item But the strongest modes are least distorted and learned first.
    \item And all modes that carry any signal are learned before any pure noise modes.
    \item Thus optimal stopping is a powerful (though sub-optimal) regularizer.
    \end{itemize}
\item Therefore:
    \begin{itemize}
    \item It's the structure in the data that drives good generalization.
    \item Generalization bounds based only on capacity for memorization are na{\"i}ve; memorization is slower than learning true structure.
    \item Multi-task learning is beneficial, especially with small (or otherwise noisy) data and well-aligned tasks.
    \item Regularization should not ignore the structure of the data.
    \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Open questions}
Many, e.g.:
\begin{itemize}
\item The intuitions presented here qualitatively generalize to the nonlinear case. Is it possible to go beyond this and get nontrivial generalization bounds for the nonlinear case? 
\item What do the structural features that cause transfer benefits look like in the nonlinear case?
\item What about signal-aligned noise?
\item Could insights about the sub-optimality of gradient descent generalize to the nonlinear case? (It's clear that gradient descent is non-optimal in non-linear cases as well, but could some other algorithm do better?)
\end{itemize}
\end{frame}

\begin{frame}[standout]
This paper will be presented at ICLR 2019, and can be found at \url{https://arxiv.org/abs/1809.10374} \\[1em]
\end{frame}

\begin{frame}[standout]
Thanks to Surya, my lab, Erin \& Pam, and you for listening!
\end{frame}

\begin{frame}[allowframebreaks]

\bibliographystyle{plainnat}
{\bibliography{generalization}}

\end{frame}

\appendix
\begin{frame}{Varying the number of inputs}
\begin{figure}[t]
\centering
\begin{subfigure}[t]{0.48\textwidth}
\includegraphics[width=\textwidth]{../../plots/paper/changing_p_A.png}
\label{supp_P_fig_A}
\end{subfigure}\\[-1em]
\begin{subfigure}[t]{0.36\textwidth}
\includegraphics[width=\textwidth]{../../plots/paper/changing_p_B.png}
\label{supp_P_fig_B}
\end{subfigure}%
\begin{subfigure}[t]{0.48\textwidth}
\includegraphics[width=\textwidth]{../../plots/paper/changing_p_C.png}
\label{supp_P_fig_C}
\end{subfigure}
\end{figure}
\end{frame}

\begin{frame}{Alignment time}
\begin{figure}
\centering
\begin{subfigure}[t]{0.3\textwidth}
\includegraphics[height=0.38\textheight]{../../plots/paper/supp_alignment_time_B.png}
\end{subfigure}%
\begin{subfigure}[t]{0.3\textwidth}
\includegraphics[height=0.38\textheight]{../../plots/paper/supp_alignment_time_C.png}
\end{subfigure}%
\begin{subfigure}[t]{0.4\textwidth}
\includegraphics[height=0.38\textheight]{../../plots/paper/supp_alignment_time_D.png}
\end{subfigure}\\
\begin{subfigure}[t]{0.3\textwidth}
\includegraphics[height=0.38\textheight]{../../plots/paper/supp_alignment_time_F.png}
\end{subfigure}%
\begin{subfigure}[t]{0.3\textwidth}
\includegraphics[height=0.38\textheight]{../../plots/paper/supp_alignment_time_G.png}
\end{subfigure}%
\begin{subfigure}[t]{0.4\textwidth}
\includegraphics[height=0.38\textheight]{../../plots/paper/supp_alignment_time_H.png}
\end{subfigure}
\end{figure}

\end{frame}


\begin{frame}{Formulas for the train and test error}
\footnotesize
\begin{align*}
\trainerr &\equiv \frac{\sum_{\mu=1}^{\overline{N_1}} \vert\vert{\bf W \bh{x}}^\mu - \bh{y}^\mu\vert\vert^2_2}{\sum_{\mu=1}^{\overline{N_1}} \vert\vert \bh{y}^\mu \vert\vert^2_2 }\\[1em]
\uncover<2->{ &= \left[\sum_{\beta=1}^{\overline{N}_3} \hat{s}_{\beta}^2\right]^{-1} 
\left[ \sum_{\alpha=1}^{N_2} s_{\alpha}^2 +  \sum_{\beta=1}^{\overline{N}_3} \hat{s}_{\beta}^2
- 2 \sum_{\alpha=1}^{N_2} \sum_{\beta=1}^{\overline{N}_3}  s_{\alpha} \hat{s}_{\beta} \left({\bf u}^{\alpha} \cdot \bf{\hat u}^{\beta} \right) \left({\bf v}^{\alpha} \cdot \bf{\hat v}^{\beta} \right)\right]\\[3em]}
\uncover<3->{\generr &\equiv   \frac{ \left\langle \vert\vert{\bf W}\bb{x} - \bb{y} \vert\vert^2_2 \right \rangle} 
                      { \left\langle  \vert\vert \bb{y} \vert\vert^2_2  \right \rangle} \\[1em]}
\uncover<4->{ &= \left[\sum_{\beta=1}^{\overline{N}_2} \overline{s}_{\beta}^2\right]^{-1} 
\left[ \sum_{\alpha=1}^{N_2} s_{\alpha}^2 +  \sum_{\beta=1}^{\overline{N}_2} \overline{s}_{\beta}^2
- 2 \sum_{\alpha=1}^{N_2} \sum_{\beta=1}^{\overline{N}_2}  s_{\alpha} \overline{s}_{\beta} \left({\bf u}^{\alpha} \cdot \bb{u}^{\beta} \right) \left({\bf v}^{\alpha} \cdot \bb{v}^{\beta} \right)\right]}
\end{align*}
\end{frame}


\end{document}


