---
title: "transfer analyses"
author: "Andrew Lampinen"
date: "October 31, 2017"
output: html_document
---

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
```

```{r}
theme_set(theme_bw() +
            theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()))
```

```{r}
nruns = 2
ndoms = c(2)
qs = c(1, 0.5, 0, -0.5, -1)
d = data.frame()
for (ndom in ndoms) {
  for (q in qs) {
    for (run in 0:(nruns-1)) {
      this_d = read.csv(sprintf("../correlation_results/loss_ndom%i_correlation%f_run%i.csv", ndom, q, run), header=T)
      this_d = this_d %>% 
        mutate(ndom=ndom, q=q, run=run)
      d = bind_rows(d, this_d)
    }
  }
}
```

```{r}
d = d %>%
  mutate(loss_per = loss/ndom,
         log_loss_per = log(loss_per),
         ndom=factor(ndom, levels=c(1,2,4,10)),
         abs_q = factor(abs(q)),
         q = factor(q),
         log_loss = log(loss))
```

```{r}
avg_d = d %>%
  group_by(q, abs_q, ndom, epoch) %>%
  summarize(loss=mean(loss), log_loss=mean(log_loss), loss_per=mean(loss_per), log_loss_per=mean(log_loss_per))
```


```{r}
ggplot(avg_d %>% filter(ndom==2), aes(x=epoch, y=log_loss_per, color=q)) +
  geom_line(size=1.5) +
  scale_color_brewer(palette='BuPu') + 
  theme_bw()
```

```{r}
ggsave("../plots/correlation_first_results.png")
```

```{r}
ggplot(avg_d %>% filter(ndom == 2), aes(x=epoch, y=log_loss, color=q)) +
  geom_line(size=1.5) +
  scale_color_brewer(palette='BuPu') + 
  ylim(-2.1, -2.0) +
  theme_bw()
```

```{r}
ggsave("../plots/correlation_first_results_zoomed_in.png")
```

```{r}
ggplot(avg_d %>% filter(q==0), aes(x=epoch, y=log_loss_per, color=ndom)) +
  geom_line(size=1.5) +
  scale_color_brewer(palette='BuPu', drop=F) + 
  theme_bw()
```
```{r}
ggsave("../plots/q0_ndom_comparison.png")
```

```{r}
ggplot(avg_d %>% filter(q==1), aes(x=epoch, y=log_loss_per, color=ndom)) +
  geom_line(size=1.5) +
  scale_color_brewer(palette='BuPu', drop=F) + 
  theme_bw()
```
```{r}
ggsave("../plots/q1_ndom_comparison.png")
```

# Orthogonal


```{r}
nruns = 10
ndoms = c(1, 2, 4, 10)
d = data.frame()
for (ndom in ndoms) {
  for (q in qs) {
    for (run in 0:(nruns-1)) {
      this_d = read.csv(sprintf("../orthogonal_transform_results/loss_ndom%i_run%i.csv", ndom, run), header=T)
      this_d = this_d %>% 
        mutate(ndom=ndom, run=run)
      d = bind_rows(d, this_d)
    }
  }
}
```

```{r}
d = d %>%
  mutate(loss_per=loss/ndom,
         ndom=factor(ndom),
         log_loss_per=log(loss_per),
         log_loss = log(loss))
```

```{r}
avg_d = d %>%
  group_by(ndom, epoch) %>%
  summarize(loss=mean(loss), log_loss=mean(log_loss), loss_per=mean(loss_per), log_loss_per=mean(log_loss_per))
```


```{r}
ggplot(avg_d, aes(x=epoch, y=log_loss_per, color=ndom)) +
  geom_line(size=1.2) +
  scale_color_brewer(palette='BuPu') + 
  theme_bw()
```
```{r}
ggsave("../plots/orthogonal_first_results.png")
```

# Eight things

```{r}
nruns = 10
features_types = c('original', 'scrambled')
d = data.frame()
for (features in features_types) {
  for (q in qs) {
    for (run in 0:(nruns-1)) {
      this_d = read.csv(sprintf("../eightthings_smallweights_results/loss_features%s_run%i.csv", features, run), header=T)
      this_d = this_d %>% 
        mutate(features=features, run=run)
      d = bind_rows(d, this_d)
    }
  }
}
```

```{r}
d = d %>%
  filter(epoch <= 1000) %>%
  mutate(features=factor(features),
         log_loss = log(loss))
```

```{r}
avg_d = d %>%
  group_by(features, epoch) %>%
  summarize(loss=mean(loss), log_loss=mean(log_loss))
```


```{r}
ggplot(avg_d, aes(x=epoch, y=log_loss, color=features)) +
  geom_line(size=1.2) +
  scale_color_brewer(palette='BuPu') + 
  theme_bw()
```
```{r}
ggsave("../plots/eightthings_slower_results.png")
```


# Eight things (with label noise)

```{r}
nruns = 50
features_types = c('original', 'scrambled')
d = data.frame()
for (features in features_types) {
  for (q in qs) {
    for (run in 0:(nruns-1)) {
      this_d = read.csv(sprintf("../eightthings_noisy_results/loss_features%s_run%i.csv", features, run), header=T)
      this_d = this_d %>% 
        mutate(features=features, run=run)
      d = bind_rows(d, this_d)
    }
  }
}
```

```{r}
d = d %>%
  filter(epoch <= 1000) %>%
  mutate(features=factor(features),
         log_loss = log(loss))
```

```{r}
avg_d = d %>%
  group_by(features, epoch) %>%
  summarize(loss=mean(loss), log_loss_sd=sd(log_loss), log_loss=mean(log_loss)) %>%
  mutate(log_loss_95_low=log_loss-1.96*log_loss_sd/sqrt(n()), log_loss_95_high=log_loss+1.96*log_loss_sd/sqrt(n())) %>%
  ungroup() %>%
  mutate(features=factor(features, labels=c("Shared structure", "No shared structure")))
```


```{r}
ggplot(avg_d, aes(x=epoch, y=log_loss, color=features)) +
  geom_line(size=1.2) +
  geom_ribbon(aes(ymin=log_loss_95_low, ymax=log_loss_95_high, fill=features), alpha=0.5) +
  scale_color_manual(values=c("#B3CDE3", "#88419D")) + 
  scale_fill_manual(values=c("#B3CDE3", "#88419D")) + 
  theme_bw()
```
```{r}
ggsave("../plots/eightthings_noisy_results.png")
```

# Shared input modes analysis

```{r}
nruns = 1
qs = c(0, 0.2, 0.39, 0.79, 1.57, 3.14)
num_domains = c(2, 10)
d = data.frame()
for (num_dom in num_domains) {
  for (q in qs) {
    for (run in 0:(nruns-1)) {
      this_d = read.csv(sprintf("../shared_input_mode_batch_results/loss_ndom%i_q%.2f_run%i.csv", num_dom, q, run), header=T)
      this_d = this_d %>% 
        mutate(q=q, num_domains=num_dom, run=run)
      d = bind_rows(d, this_d)
    }
  }
}
```

```{r}
d = d %>%
  filter(q < 3.14) %>%
  mutate(q=factor(q),
         num_domains=factor(num_domains),
         log_loss = log(loss))
```

```{r}
avg_d = d %>%
  group_by(q, num_domains, epoch) %>%
  summarize(loss=mean(loss), log_loss_sd=sd(log_loss), log_loss=mean(log_loss)) %>%
  mutate(log_loss_95_low=log_loss-1.96*log_loss_sd/sqrt(n()), log_loss_95_high=log_loss+1.96*log_loss_sd/sqrt(n())) %>%
  ungroup()
```


```{r}
ggplot(avg_d %>% filter(epoch < 2000), aes(x=epoch, y=log_loss, color=q)) +
  geom_line(size=1.2) +
#  geom_ribbon(aes(ymin=log_loss_95_low, ymax=log_loss_95_high, fill=features), alpha=0.5) +
  scale_color_brewer(palette="BuPu") + 
  ylab("Log generalization loss") +
  xlab("Epoch") +
  guides(color=guide_legend(title=bquote(phi))) +
  facet_wrap(~ num_domains) 
```
```{r}
ggsave("../plots/shared_input_modes_batch_results.png")
```


# Single domain generalization analyses

```{r}
nruns = 10
noise_vars = c(0., 0.025, 0.05, 0.1, 0.2)
output_sizes= c(10, 50, 100, 200, 400)
d = data.frame()
for (noise_var in noise_vars) {
  for (output_size in output_sizes) {
    for (run in 0:(nruns-1)) {
      this_d = read.csv(sprintf("../single_generalization_results/noise_var_%.2f_output_size_%i_run_%i.csv", noise_var, output_size, run), header=T)
      this_d = this_d %>% 
        mutate(noise_var=noise_var, output_size=output_size, run=run)
      d = bind_rows(d, this_d)
    }
  }
}
```

```{r}
d = d %>%
  mutate(output_size=factor(output_size),
         noise_var=factor(noise_var),
         log_loss = log(loss))
```

```{r}
avg_d = d %>%
  group_by(noise_var, output_size, epoch) %>%
  summarize(loss=mean(loss), log_loss_sd=sd(log_loss), log_loss=mean(log_loss)) %>%
  mutate(log_loss_95_low=log_loss-1.96*log_loss_sd/sqrt(n()), log_loss_95_high=log_loss+1.96*log_loss_sd/sqrt(n())) %>%
  ungroup()
```


```{r}
ggplot(avg_d %>% filter(output_size != 400), aes(x=epoch, y=log_loss, color=noise_var)) +
  geom_line(size=1.2) +
#  geom_ribbon(aes(ymin=log_loss_95_low, ymax=log_loss_95_high, fill=features), alpha=0.5) +
  scale_color_brewer(palette="YlOrRd") + 
  ylab("Log generalization loss") +
  xlab("Epoch") +
  guides(color=guide_legend(title="Noise Variance")) +
  facet_wrap(~ output_size) 
```
```{r}
ggsave("../plots/single_domain_generalization_curves.png")
```


## comparing input types
```{r}
nruns = 10
noise_vars = c(0., 0.025, 0.05, 0.1, 0.2)
output_sizes= c(10, 50, 100, 200, 400)
input_types = c("one_hot", "ortho", "gauss")
d = data.frame()
for (noise_var in noise_vars) {
  for (output_size in output_sizes) {
    for (input_type in input_types) {
      for (run in 0:(nruns-1)) { 
        if (input_type == "one_hot") {
          this_d = read.csv(sprintf("../single_generalization_results/noise_var_%.2f_output_size_%i_run_%i.csv", noise_var, output_size, run), header=T)
        } else {
          this_d = read.csv(sprintf("../single_generalization_%s_inputs_results/noise_var_%.2f_output_size_%i_run_%i.csv", input_type, noise_var, output_size, run), header=T)
        }
        this_d = this_d %>% 
          mutate(noise_var=noise_var, output_size=output_size, run=run, input_type=input_type)
        d = bind_rows(d, this_d)
      }
    }
  }
}
```

```{r}
d = d %>%
  mutate(output_size=factor(output_size),
         input_type=factor(input_type, levels=c("one_hot", "gauss", "ortho"), labels=c("One-hot", "Random Gaussian", "Random orthonormal")),
         noise_var=factor(noise_var),
         log_loss = log(loss))
```

```{r}
avg_d = d %>%
  group_by(noise_var, output_size, epoch, input_type) %>%
  summarize(loss=mean(loss), log_loss_sd=sd(log_loss), log_loss=mean(log_loss)) %>%
  mutate(log_loss_95_low=log_loss-1.96*log_loss_sd/sqrt(n()), log_loss_95_high=log_loss+1.96*log_loss_sd/sqrt(n())) %>%
  ungroup()
```


```{r}
ggplot(avg_d %>% filter(output_size == 100), aes(x=epoch, y=log_loss, color=noise_var, linetype=input_type)) +
  geom_line(size=1.2) +
#  geom_ribbon(aes(ymin=log_loss_95_low, ymax=log_loss_95_high, fill=features), alpha=0.5) +
  scale_color_brewer(palette="YlOrRd") + 
  ylab("Log generalization loss") +
  xlab("Epoch") +
  guides(color=guide_legend(title="Noise Variance"), linetype=guide_legend(title="Input type")) 
```

```{r}
ggsave("../plots/input_types_dont_matter.png")
```


## comparing to theory
```{r}
nruns = 1
noise_vars = c(1., 25., 100., 10000.)#, 1600., 10000.)
output_sizes= c(100)
d = data.frame()
for (noise_var in noise_vars) {
  for (output_size in output_sizes) {
    for (run in 0:(nruns-1)) { 
      this_d = read.csv(sprintf("../single_generalization_full_results_notf/noise_var_%.2f_output_size_%i_run_%i.csv", noise_var, output_size, run), header=T)

      this_d = this_d %>% 
        mutate(noise_var=noise_var, output_size=output_size, run=run, type="Empirical")
      d = bind_rows(d, this_d)
    }
  }
  this_d = read.csv(sprintf("../single_generalization_full_results_notf/noise_var_%.2f_theory_track.csv", noise_var), header=T)

  this_d = this_d %>% 
    rename(loss=generalization_error) %>%
    mutate(noise_var=noise_var, output_size=NA, run=NA, type="Theory")
  d = bind_rows(d, this_d)
}
```

```{r}
d = d %>%
  mutate(output_size=factor(output_size),
         noise_var=factor(noise_var),
         type=factor(type),
         log_loss = log(loss))
```

```{r}
other_d = d %>%
  filter(type=="Theory") %>%
  group_by(noise_var, output_size, epoch) %>%
  summarize(s = mean(s))
```


```{r}
avg_d = d %>%
  group_by(noise_var, output_size, epoch, type) %>%
  summarize(loss=mean(loss), log_loss_sd=sd(log_loss), log_loss=mean(log_loss)) %>%
  mutate(log_loss_95_low=log_loss-1.96*log_loss_sd/sqrt(n()), log_loss_95_high=log_loss+1.96*log_loss_sd/sqrt(n())) %>%
  ungroup()
```


```{r}
ggplot(avg_d , aes(x=epoch, y=log_loss, color=noise_var, linetype=type)) +
  geom_line(size=1.2) +
#  geom_ribbon(aes(ymin=log_loss_95_low, ymax=log_loss_95_high, fill=features), alpha=0.5) +
  scale_color_brewer(palette="YlOrRd") + 
  ylab("Log generalization loss") +
  xlab("Epoch") +
  guides(color=guide_legend(title="Noise Variance"), linetype=guide_legend(title="Theory or empirical")) 
```

```{r}
# ggplot(avg_svd_d %>% filter(mode_rank==0), aes(x=log(epoch), y=log(s))) +
#   geom_line(size=1.2) +
# #  geom_line(aes(y=diag), color="blue", size=1.2) +
#   geom_line(data = other_d, aes(y=log(s/10)), color="yellow", linetype=2, size=1.2) +
# #  geom_ribbon(aes(ymin=log_loss_95_low, ymax=log_loss_95_high, fill=features), alpha=0.5) +
#   ylab("Log generalization loss") +
#   xlab("Epoch") +
#   guides(color=guide_legend(title="Noise Variance"), linetype=guide_legend(title="Theory or empirical")) 

```

```{r}
ggsave("../plots/theory_and_empirical_full_rank_N2_90.png")
```

## aligned vs non-aligned
```{r}
nruns = 5
noise_vars = c(1.)
output_sizes= c(100)
svms = 1:10
alignments = c("True", "False")
d = data.frame()
for (noise_var in noise_vars) {
  for (output_size in output_sizes) {
    for (svm in svms) {
      for (aligned in alignments) {
        for (run in 0:(nruns-1)) { 
          this_d = read.csv(sprintf("../single_generalization_comparison_results/noise_var_%.2f_output_size_%i_svm_%f_aligned_%s_run_%i.csv", noise_var, output_size, svm, aligned, run), header=T)
    
          this_d = this_d %>% 
            mutate(noise_var=noise_var, output_size=output_size, svm=svm, aligned=aligned=="True", run=run, type="Empirical")
          d = bind_rows(d, this_d)
        }
      }
      this_d = read.csv(sprintf("../single_generalization_comparison_results/noise_var_%.2f_svm_%f_theory_track.csv", noise_var, svm), header=T)
    
      this_d = this_d %>% 
        rename(loss=generalization_error) %>%
        mutate(noise_var=noise_var, output_size=NA,  svm=svm, aligned=aligned=="True", run=NA, type="Theory")
      d = bind_rows(d, this_d)
    }
  }
}
```

```{r}
d = d %>%
  mutate(output_size=factor(output_size),
         noise_var=factor(noise_var),
         svm=factor(svm),
         aligned=factor(aligned),
         type=factor(type),
         log_loss = log(loss))
```

```{r}
min_d = d %>%
  group_by(svm, aligned, noise_var, type, run) %>%
  summarize(min_Eg = min(log_loss), min_t = which.min(log_loss)) %>%
  ungroup() %>%
  group_by(svm, aligned, noise_var, type) %>%
  summarize(avg_min_Eg = mean(min_Eg), sd_min_Eg = sd(min_Eg),
            avg_min_t = mean(min_t), sd_min_t = sd(min_t),
            se_min_Eg = sd_min_Eg/sqrt(n()), ci_Eg_up= avg_min_Eg + 1.96*se_min_Eg, ci_Eg_lo= avg_min_Eg - 1.96*se_min_Eg,
            se_min_t = sd_min_t/sqrt(n()), ci_t_up= avg_min_t + 1.96*se_min_t, ci_t_lo= avg_min_t - 1.96*se_min_t) %>%
  ungroup()
  
```



```{r}
avg_d = d %>%
  group_by(noise_var, output_size, svm, aligned, epoch, type) %>%
  summarize(loss=mean(loss), log_loss_sd=sd(log_loss), log_loss=mean(log_loss)) %>%
  mutate(log_loss_95_low=log_loss-1.96*log_loss_sd/sqrt(n()), log_loss_95_high=log_loss+1.96*log_loss_sd/sqrt(n())) %>%
  ungroup() %>%
  mutate(new_type = ifelse(type == "Theory", "Theory",
                            ifelse(aligned == "TRUE", "Empirical aligned", "Empirical random"))) %>%
  mutate(new_type = factor(new_type, levels=c("Theory", "Empirical aligned", "Empirical random")))
```


```{r}
ggplot(avg_d, aes(x=epoch, y=log_loss, color=as.numeric(svm), linetype=new_type, group=interaction(new_type,svm))) +
  geom_line(size=1.2) +
#  geom_ribbon(aes(ymin=log_loss_95_low, ymax=log_loss_95_high, fill=features), alpha=0.5) +
  scale_color_gradient(low="#0000FF", high="#FF0000") +
  ylab("Log generalization loss") +
  xlab("Epoch") +
  guides(color=guide_legend(title="SNR"), linetype=guide_legend(title="Theory or empirical"))
```

```{r}
ggsave("../plots/theory_empirical_alignment.png")
```
```{r}
wide_min_d = min_d %>% 
  filter(type == "Empirical") %>%
  select(-type, -se_min_Eg, -se_min_t) %>%
  gather(metric, measurement, avg_min_Eg, sd_min_Eg, avg_min_t, sd_min_t, ci_t_up, ci_t_lo, ci_Eg_up, ci_Eg_lo) %>%
  mutate(aligned = ifelse(aligned=="TRUE", "Aligned", "Random")) %>%
  unite(am, aligned, metric) %>%
  spread(am, measurement)
```


```{r}
ggplot(data=wide_min_d, aes(x=Aligned_avg_min_Eg, y=Random_avg_min_Eg, color=as.integer(svm))) +
  scale_color_gradient(low="#0000FF", high="#FF0000", limits=c(1, 10), breaks=c(1,10))  +
  geom_abline(aes(intercept=0, slope=1), alpha=0.5, linetype=3) +
  labs(x="Min log generalization error (aligned initialization)",
       y="Min log generalization error (random initialization)") +
  geom_point() +
  geom_errorbar(aes(ymin=Random_ci_Eg_lo, ymax=Random_ci_Eg_up), width=0.05) +
  geom_errorbarh(aes(xmin=Aligned_ci_Eg_lo, xmax=Aligned_ci_Eg_up), height=0.05) +
  guides(color=guide_colorbar(title="SNR"))
```

```{r}
ggsave("../plots/min_Eg_aligned_vs_random.png")
```

```{r}

```


```{r}
ggplot(data=wide_min_d, aes(x=Aligned_avg_min_t, y=Random_avg_min_t, color=as.integer(svm))) +
  scale_color_gradient(low="#0000FF", high="#FF0000", limits=c(1, 10), breaks=c(1,10))  +
  geom_abline(aes(intercept=0, slope=1), alpha=0.5, linetype=3) +
  labs(x="Best generaliation epoch (aligned initialization)",
       y="Best generaliation epoch (random initialization)") +
  geom_point() +
  geom_errorbar(aes(ymin=Random_ci_t_lo, ymax=Random_ci_t_up), width=5) +
  geom_errorbarh(aes(xmin=Aligned_ci_t_lo, xmax=Aligned_ci_t_up), height=5) +
  guides(color=guide_colorbar(title="SNR"))
```

```{r}
ggsave("../plots/min_t_aligned_vs_random.png")
```
```{r}
min_d2 = min_d %>% 
  mutate(this_type=ifelse(type=="Theory", "Theory",
                          ifelse(aligned == "TRUE", "Empirical-aligned", "Empirical-random"))) %>%
  select(-type, -aligned, -se_min_Eg, -se_min_t) 
```

```{r}
ggplot(data=min_d2, aes(x=avg_min_t, y=avg_min_Eg, color=as.integer(svm), shape=this_type)) +
  scale_color_gradient(low="#0000FF", high="#FF0000", limits=c(1, 10), breaks=c(1,10))  +
#  geom_abline(aes(intercept=0, slope=1), alpha=0.5, linetype=3) +
  labs(x="Best generalization epoch",
       y="Best log generalization error") +
  geom_point() +
  geom_errorbar(aes(ymin=ci_Eg_lo, ymax=ci_Eg_up), width=7) +
  geom_errorbarh(aes(xmin=ci_t_lo, xmax=ci_t_up), height=0.05) +
  guides(color=guide_colorbar(title="SNR"), shape=guide_legend(title="Type"))
```

```{r}
ggsave("../plots/min_Eg_vs_min_t.png")
```
```{r}
ggplot(data=min_d2 %>% filter(this_type != "Theory"), aes(x=avg_min_t, y=avg_min_Eg, color=as.integer(svm), shape=this_type)) +
  scale_color_gradient(low="#0000FF", high="#FF0000", limits=c(1, 10), breaks=c(1,10))  +
#  geom_abline(aes(intercept=0, slope=1), alpha=0.5, linetype=3) +
  labs(x="Best generalization epoch",
       y="Best log generalization error") +
  geom_point() +
  geom_errorbar(aes(ymin=ci_Eg_lo, ymax=ci_Eg_up), width=7) +
  geom_errorbarh(aes(xmin=ci_t_lo, xmax=ci_t_up), height=0.05) +
  guides(color=guide_colorbar(title="SNR"), shape=guide_legend(title="Type"))
```

```{r}
ggsave("../plots/min_Eg_vs_min_t_no_theory.png")
```